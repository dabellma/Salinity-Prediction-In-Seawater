{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Feature 0: entero\n",
    "- Feature 1:  water_temp\n",
    "- Feature 2: do\n",
    "- Feature 3: ph\n",
    "- Feature 4: chlorophyll\n",
    "- Feature 5: density\n",
    "- Feature 6: fecal\n",
    "- Feature 7:  air_temp\n",
    "- Feature 8:  humidity\n",
    "- Feature 9: windspeed \n",
    "- Feature 10: cloud_cover\n",
    "- Feature 11: solar_radiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pearson Neural Net Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salinity pearson array:\n",
      "[ 0.235  0.401  0.189  0.194  0.192 -0.39   0.363  0.733  0.113  0.376\n",
      "  0.03   0.38 ]\n",
      "Rankings:\n",
      "[7, 11, 4, 6, 5, 1, 8, 12, 3, 9, 2, 10]\n"
     ]
    }
   ],
   "source": [
    "# create pearson array\n",
    "pearson = np.array([0.235, 0.401, 0.189, 0.194, 0.192, -0.390, 0.363, 0.733, 0.113, 0.376, 0.030, 0.380])\n",
    "# create an array of the rankings\n",
    "sorted_pearson = sorted(range(len(pearson)), key=lambda i: pearson[i])\n",
    "pearson_ranks = [sorted_pearson.index(i) + 1 for i in range(len(pearson))]\n",
    "# print info\n",
    "print(\"Salinity pearson array:\")\n",
    "print(pearson)\n",
    "print(\"Rankings:\")\n",
    "print(pearson_ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pearson Pair-wise Features Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Coefficient Matrix \n",
      "[[ 0.    0.03  0.11  0.09  0.13 -0.07  0.78 -0.05  0.04  0.03  0.05 -0.  ]\n",
      " [ 0.03  0.    0.51  0.57  0.05 -0.98  0.01  0.36  0.18  0.15  0.07  0.06]\n",
      " [ 0.11  0.51  0.    0.69  0.23 -0.54  0.09  0.06  0.12  0.17  0.1   0.06]\n",
      " [ 0.09  0.57  0.69  0.    0.25 -0.53  0.07  0.12  0.07  0.25  0.04  0.22]\n",
      " [ 0.13  0.05  0.23  0.25  0.   -0.02  0.1   0.08  0.09  0.07  0.03  0.08]\n",
      " [-0.07 -0.98 -0.54 -0.53 -0.02  0.   -0.06 -0.34 -0.18 -0.13 -0.05 -0.01]\n",
      " [ 0.78  0.01  0.09  0.07  0.1  -0.06  0.   -0.06  0.04  0.05  0.04  0.02]\n",
      " [-0.05  0.36  0.06  0.12  0.08 -0.34 -0.06  0.   -0.34  0.41 -0.24  0.51]\n",
      " [ 0.04  0.18  0.12  0.07  0.09 -0.18  0.04 -0.34  0.    0.08  0.48 -0.34]\n",
      " [ 0.03  0.15  0.17  0.25  0.07 -0.13  0.05  0.41  0.08  0.    0.03  0.5 ]\n",
      " [ 0.05  0.07  0.1   0.04  0.03 -0.05  0.04 -0.24  0.48  0.03  0.   -0.48]\n",
      " [-0.    0.06  0.06  0.22  0.08 -0.01  0.02  0.51 -0.34  0.5  -0.48  0.  ]]\n",
      "P-values Matrix\n",
      "[[0.   0.24 0.   0.   0.   0.   0.   0.04 0.08 0.21 0.06 1.  ]\n",
      " [0.24 0.   0.   0.   0.06 0.   0.54 0.   0.   0.   0.   0.02]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.02 0.   0.   0.   0.01]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.01 0.   0.13 0.  ]\n",
      " [0.   0.06 0.   0.   0.   0.39 0.   0.   0.   0.   0.22 0.  ]\n",
      " [0.   0.   0.   0.   0.39 0.   0.02 0.   0.   0.   0.02 0.69]\n",
      " [0.   0.54 0.   0.   0.   0.02 0.   0.02 0.13 0.04 0.14 0.31]\n",
      " [0.04 0.   0.02 0.   0.   0.   0.02 0.   0.   0.   0.   0.  ]\n",
      " [0.08 0.   0.   0.01 0.   0.   0.13 0.   0.   0.   0.   0.  ]\n",
      " [0.21 0.   0.   0.   0.   0.   0.04 0.   0.   0.   0.29 0.  ]\n",
      " [0.06 0.   0.   0.13 0.22 0.02 0.14 0.   0.   0.29 0.   0.  ]\n",
      " [1.   0.02 0.01 0.   0.   0.69 0.31 0.   0.   0.   0.   0.  ]]\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "data_df = pd.read_csv('water_quality_and_weather.csv')\n",
    "# drop columns that are not featues\n",
    "data_df.drop(columns=['station', 'Date', 'Time', 'SALINITY'], inplace=True)\n",
    "# initialize matrices \n",
    "num_vars = 12\n",
    "corr_coef = np.zeros((num_vars, num_vars))\n",
    "p_vals = np.zeros((num_vars, num_vars))\n",
    "# fill matrices with pair-wise pearson relationships\n",
    "for i in range(num_vars):\n",
    "    for j in range(num_vars):\n",
    "        corr_coef[i, j],  p_vals[i, j] = pearsonr(data_df.iloc[:, i], data_df.iloc[:, j])\n",
    "# ignore relationship with itself\n",
    "np.fill_diagonal(corr_coef, 0)\n",
    "# print info \n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "print(\"Correlation Coefficient Matrix \")\n",
    "print(corr_coef)\n",
    "print(\"P-values Matrix\")\n",
    "print(p_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted features array:\n",
      "[ 0.11  0.16  0.2   0.23  0.1  -0.31  0.09  0.15 -0.03  0.2  -0.05  0.15]\n",
      "Rankings:\n",
      "[6, 9, 11, 12, 5, 1, 4, 8, 3, 10, 2, 7]\n"
     ]
    }
   ],
   "source": [
    "# create empty array\n",
    "weighted_feaures = np.array([])\n",
    "# dot product (salinity rankings) x (pairwise features matrix)\n",
    "for c in corr_coef:\n",
    "    weigh_features = c * pearson_ranks\n",
    "    weigh_result = np.sum(weigh_features)\n",
    "    weighted_feaures = np.append(weighted_feaures, weigh_result)\n",
    "# normalize the array\n",
    "normalized_featureWeights = weighted_feaures / np.sum(weighted_feaures)\n",
    "# create an array of the rankings\n",
    "sorted_featureWeights = sorted(range(len(normalized_featureWeights)), key=lambda i: normalized_featureWeights[i])\n",
    "featureWeights_ranks = [sorted_featureWeights.index(i) + 1 for i in range(len(normalized_featureWeights))]\n",
    "# print info \n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "print(\"Weighted features array:\")\n",
    "print(normalized_featureWeights)\n",
    "print(\"Rankings:\")\n",
    "print(featureWeights_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined weights before normalization: \n",
      "[  4.14   6.2    7.73   8.69   3.79 -11.75   3.72   6.11  -1.01   7.6\n",
      "  -1.97   5.91]\n",
      "Combined weights after normalization: \n",
      "[ 0.11  0.16  0.2   0.22  0.1  -0.3   0.09  0.16 -0.03  0.19 -0.05  0.15]\n",
      "Ranks:\n",
      "[6, 9, 11, 12, 5, 1, 4, 8, 3, 10, 2, 7]\n"
     ]
    }
   ],
   "source": [
    "# Combine weighted pair-wise featues & sailinty relatons (70/30 weighted split)\n",
    "alpha = 0.5\n",
    "beta = 0.5\n",
    "combined_weights = alpha * pearson + beta * weighted_feaures\n",
    "\n",
    "# normalize\n",
    "normalize_combined = combined_weights / np.sum(combined_weights) \n",
    "# create an array of the rankings\n",
    "sorted_combined = sorted(range(len(normalized_featureWeights)), key=lambda i: normalized_featureWeights[i])\n",
    "combined_ranks = [sorted_combined.index(i) + 1 for i in range(len(normalized_featureWeights))]\n",
    "# print info\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "print(\"Combined weights before normalization: \")\n",
    "print(combined_weights)\n",
    "print(\"Combined weights after normalization: \")\n",
    "print(normalize_combined)\n",
    "print(\"Ranks:\")\n",
    "print(combined_ranks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
